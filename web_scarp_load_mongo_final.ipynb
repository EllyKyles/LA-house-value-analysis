{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import random\n",
    "from lxml.html import fromstring\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import copy\n",
    "from itertools import cycle\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download new driver from http://chromedriver.storage.googleapis.com/81.0.4044.138/chromedriver_win32.zip\n",
      "Unpack archive C:\\Users\\blkyl\\.wdm\\drivers\\chromedriver\\81.0.4044.138\\win32\\chromedriver.zip\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\blkyl\\.wdm\\drivers\\chromedriver\\81.0.4044.138\\win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.get('https://www.realtor.com/realestateandhomes-search/Los-Angeles_CA');\n",
    "time.sleep(5) # Let the user actually see something!\n",
    "\n",
    "#find the last page of realtor.com\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "num_page = int(soup.find('div', class_=\"pagination-wrapper srp-pagination-bottom\")\n",
    "    .find_all('span')[-2]\n",
    "    .text.strip())\n",
    "\n",
    "\n",
    "la_house_info=[]\n",
    "for i in range(num_page):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    code_soup = soup.find_all('div', attrs={'class': 'photo-wrap'})\n",
    "    for house in code_soup:\n",
    "        results = house.find_all('a')\n",
    "        for result in results:\n",
    "            la_house_info.append(result['href'])\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/realestateandhomes-detail/155-W-58th-St_Los-Angeles_CA_90037_M22496-25680',\n",
       " '/realestateandhomes-detail/1838-W-88th-Pl_Los-Angeles_CA_90047_M15937-65911',\n",
       " '/realestateandhomes-detail/14141-Dickens-St-Apt-305_Sherman-Oaks_CA_91423_M23888-95508',\n",
       " '/realestateandhomes-detail/746-S-Los-Angeles-St-Apt-604_Los-Angeles_CA_90014_M13749-42069',\n",
       " '/realestateandhomes-detail/1130-W-83rd-St_Los-Angeles_CA_90044_M15275-81597']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_house_info[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11403"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(la_house_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "picked la house's urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('la_house_info.pickle', 'wb') as f:\n",
    "    pickle.dump(la_house_info,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window users needs to specify the path where webdriver can run!\n",
    "#mac users doesn't need to specify it\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\blkyl\\.wdm\\drivers\\chromedriver\\81.0.4044.138\\win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lrvine Ca house info\n",
    "\n",
    "driver.get('https://www.realtor.com/realestateandhomes-search/Irvine_CA');\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "#soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#num_page = int(soup.find('div', class_=\"pagination-wrapper srp-pagination-bottom\")\n",
    "#    .find_all('span')[-2]\n",
    "#    .text.strip())\n",
    "#driver.quit()\n",
    "\n",
    "lrvine_house_info=[]\n",
    "for i in range(24):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    code_soup = soup.find_all('div', attrs={'class': 'photo-wrap'})\n",
    "    for house in code_soup:\n",
    "        results = house.find_all('a')\n",
    "        for result in results:\n",
    "            lrvine_house_info.append(result['href'])\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/realestateandhomes-detail/138-Monroe-231_Irvine_CA_92620_M21962-94507',\n",
       " '/realestateandhomes-detail/125-Chantilly-101_Irvine_CA_92620_M21002-47822',\n",
       " '/realestateandhomes-detail/5200-Irvine-Blvd-Spc-181_Irvine_CA_92620_M11726-67911',\n",
       " '/realestateandhomes-detail/4-Petersburg_Irvine_CA_92620_M11247-41649',\n",
       " '/realestateandhomes-detail/1503-Terra-Bella_Irvine_CA_92602_M18219-00000']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrvine_house_info[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "picked lrvine's house urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lrvine_house_info.pickle', 'wb') as f:\n",
    "    pickle.dump(lrvine_house_info,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THis function is to retrieve the house information using beautiful soup!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sema = asyncio.BoundedSemaphore(30)\n",
    "async def fetch(url, session):\n",
    "    async with sema, session.get(url) as response:\n",
    "        return await response.read()\n",
    "    \n",
    "    \n",
    "async def run_urls(house_info):\n",
    "    tasks = []\n",
    "    async with ClientSession() as session:\n",
    "        for url in house_info:\n",
    "            house_url = 'https://www.realtor.com'+ url\n",
    "            task = asyncio.ensure_future(fetch(house_url, session))\n",
    "            tasks.append(task)\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        return responses\n",
    "\n",
    "\n",
    "def house(soup):\n",
    "    house_info = (soup.find('ul', class_= \"property-meta list-horizontal list-style-disc list-spaced\").find_all('span', attrs={'class':'data-value'}))\n",
    "    house_info_dict ={}\n",
    "    for i,v in enumerate(house_info):\n",
    "        if i == 0:\n",
    "            house_info_dict['beds'] = house_info[i].text\n",
    "        if i == 1:\n",
    "            house_info_dict['baths'] = house_info[i].text\n",
    "        if i == 2:\n",
    "            house_info_dict['sqft'] = house_info[i].text\n",
    "        if i == 3:\n",
    "            house_info_dict['lot'] = house_info[i].text\n",
    "    \n",
    "    return house_info_dict\n",
    "\n",
    "def price(soup):\n",
    "    return soup.find('span', attrs={'itemprop':'price'}).text.replace('\\n','').strip() \n",
    "\n",
    "def pro_info(soup):\n",
    "    result = soup.find_all('div', class_='key-fact-data ellipsis')\n",
    "    pro_info_dict ={}\n",
    "    for i,v in enumerate(result):\n",
    "        if i == 0:\n",
    "            pro_info_dict['status'] = result[i].text.replace('\\n','').strip()\n",
    "        if i == 1:\n",
    "            pro_info_dict['price_per_sqft'] = result[i].text\n",
    "        if i == 2:\n",
    "            pro_info_dict['past_time'] = result[i].text\n",
    "        if i == 3:\n",
    "            pro_info_dict['house_type'] = result[i].text\n",
    "        if i == 4:\n",
    "            pro_info_dict['built_year'] = result[i].text\n",
    "            \n",
    "    return pro_info_dict \n",
    "\n",
    "\n",
    "def history_list(soup):\n",
    "    history_tb = soup.find_all('table', class_= 'table')[1].find_all('tr')\n",
    "    history_rows = [] \n",
    "    empty_row = {\"Date\": None, \"Event\": None, \"Price\": None ,\"Price/Sq Ft\": None, \"Source\": None}\n",
    "    for row in history_tb[1:]:\n",
    "        new_row = copy.copy(empty_row)\n",
    "        columns = row.find_all(\"td\")\n",
    "        new_row['Date'] = columns[0].text.strip()\n",
    "        new_row['Event'] = columns[1].text.strip()\n",
    "        new_row['Price'] = columns[2].text.strip()\n",
    "        new_row['Price/Sq Ft'] = columns[3].text.strip()\n",
    "        new_row['Source'] = columns[4].text.strip()\n",
    "        history_rows.append(new_row) \n",
    "    return history_rows\n",
    "\n",
    "\n",
    "def school_list(soup):\n",
    "    school_tb = soup.find_all('table', class_= 'table')[0].find_all('tr')\n",
    "    school_rows = [] \n",
    "    empty_row = {\"Rating\": None, \"School Name\": None, \"Grades\": None ,\"Distance\": None}\n",
    "    for row in school_tb[1:]:\n",
    "        new_row = copy.copy(empty_row)\n",
    "        columns = row.find_all(\"td\")\n",
    "        new_row['Rating'] = columns[0].text.strip()\n",
    "        new_row['School Name'] = columns[1].text.strip()\n",
    "        new_row['Grades'] = columns[2].text.strip()\n",
    "        new_row['Distance'] = columns[3].text.strip()\n",
    "        school_rows.append(new_row) \n",
    "    return school_rows\n",
    "\n",
    "def neighbor_list(soup):\n",
    "    neighbor_tb = soup.find_all('li',class_= 'clearfix text-center')\n",
    "    neighbor_rows = []\n",
    "    empty_row = {\"price\": None, \"lat\": None, \"log\": None}\n",
    "    for row in neighbor_tb:\n",
    "        new_row = copy.copy(empty_row)\n",
    "        new_row['price'] = (row.find_all('div')[1]).text\n",
    "        new_row['lat'] = (row.find_all('span')[-1]).find_all('meta')[0][\"content\"]\n",
    "        new_row['log'] = (row.find_all('span')[-1]).find_all('meta')[1][\"content\"]\n",
    "        neighbor_rows.append(new_row)  \n",
    "    return neighbor_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "from pymongo import MongoClient\n",
    "import pprint \n",
    "remote_client = MongoClient(\"127.0.0.1\", 27017)\n",
    "db = remote_client.house\n",
    "la = db.la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrieve data that I am interested in and then load it into mongoserver. \n",
    "\n",
    "In order to webscraping successfully from realtor.com which doesn't want to share their data with public, the following additional steps are needed:\n",
    "\n",
    "1. rotate proxies (change IP address by each request)\n",
    "\n",
    "2. time sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "    url = '--' # I didn't put the website that sells ip address to rotate proxies\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:10]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['118.174.234.28:31994', '185.89.0.233:34927', '88.99.10.248:1080']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies = list(get_proxies())\n",
    "proxies[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy=random.choice(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, url in enumerate(la_house_info):\n",
    "    house_data = {}\n",
    "    time.sleep(100)\n",
    "    r = requests.get('https://www.realtor.com'+ url, proxies={'http':porxy, 'https':proxy})\n",
    "    if r.status_code == 200:\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        house_data['id'] = i\n",
    "        house_data['address'] = url\n",
    "        house_data['price'] = price(soup)\n",
    "        house_data['info'] = house(soup)\n",
    "        house_data[\"area\"] = (soup.find('div', class_='neighborhood-max-width-sm padding-bottom')\n",
    "                                  .find('a').text)\n",
    "        house_data['info'] = pro_info(soup)    \n",
    "        house_data['history'] = history_list(soup)\n",
    "        house_data['school'] = school_list(soup)\n",
    "        house_data['neighbor'] = neighbor_list(soup)\n",
    "        \n",
    "    else:\n",
    "        house_data['id'] = i\n",
    "        house_data['url'] = url\n",
    "        house_data['error'] = r.status_code\n",
    "\n",
    "    la.insert_one(house_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 11402,\n",
       " 'address': '/realestateandhomes-detail/1155-S-Grand-Ave-Apt-605_Los-Angeles_CA_90015_M25085-25663',\n",
       " 'price': '$669,000',\n",
       " 'info': {'status': 'Active',\n",
       "  'price_per_sqft': '$637',\n",
       "  'past_time': '79 days',\n",
       "  'house_type': 'Condo/Townhome/Row Home/Co-Op',\n",
       "  'built_year': '2008'},\n",
       " 'area': 'Downtown Los Angeles',\n",
       " 'history': [{'Date': '02/21/2020',\n",
       "   'Event': 'Listed',\n",
       "   'Price': '$669,000',\n",
       "   'Price/Sq Ft': '$637',\n",
       "   'Source': 'CLAW'},\n",
       "  {'Date': '07/30/2009',\n",
       "   'Event': 'Sold',\n",
       "   'Price': '$415,000',\n",
       "   'Price/Sq Ft': '$395',\n",
       "   'Source': ''}],\n",
       " 'school': [{'Rating': '4',\n",
       "   'School Name': 'Ninth Street School',\n",
       "   'Grades': 'K–5',\n",
       "   'Distance': '1.0 mi'},\n",
       "  {'Rating': '2',\n",
       "   'School Name': 'John H. Liechty Middle School',\n",
       "   'Grades': '6–8',\n",
       "   'Distance': '1.0 mi'},\n",
       "  {'Rating': '3',\n",
       "   'School Name': 'Belmont Senior High School',\n",
       "   'Grades': '9–12',\n",
       "   'Distance': '1.4 mi'},\n",
       "  {'Rating': 'NR',\n",
       "   'School Name': 'Abram Friedman Occupational School',\n",
       "   'Grades': '',\n",
       "   'Distance': '0.4 mi'},\n",
       "  {'Rating': 'NR',\n",
       "   'School Name': 'Tri-C Community Day School',\n",
       "   'Grades': '7–12',\n",
       "   'Distance': '0.8 mi'},\n",
       "  {'Rating': '8',\n",
       "   'School Name': 'Alliance Dr. Olga Mohan High School',\n",
       "   'Grades': '9–12',\n",
       "   'Distance': '0.6 mi'},\n",
       "  {'Rating': 'NR',\n",
       "   'School Name': 'Immaculate Conception Private School',\n",
       "   'Grades': 'K–8',\n",
       "   'Distance': '0.8 mi'},\n",
       "  {'Rating': 'NR',\n",
       "   'School Name': 'Star Christian Private School',\n",
       "   'Grades': 'K–6',\n",
       "   'Distance': '0.9 mi'}],\n",
       " 'neighbor': [{'price': '$734,000', 'lat': '34.041456', 'log': '-118.262625'},\n",
       "  {'price': '$790,000', 'lat': '34.040804', 'log': '-118.263194'},\n",
       "  {'price': '$724,600', 'lat': '34.040804', 'log': '-118.263194'},\n",
       "  {'price': '$775,200', 'lat': '34.040804', 'log': '-118.263194'},\n",
       "  {'price': '$730,800', 'lat': '34.040804', 'log': '-118.263194'}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
